Transl8

- A smart, high-utility application designed for assisting in live translation by combining Computer Vision, Image Processing, and strong UI/Frontend fundaments.

- How does it work?
  Leveraging the power of various IOS Frameworks such as SwiftUI, CoreImage, ARKit, SceneKit, Vision, and Foundation, we created an idea to piece together and aid foreign individuals.
  By grabbing images from ARKit and processing the data, we are able to then isolate the words out the picture. These words are then fed into a Google Cloud API, where Google's neural machine
  returns the translated text. From there, the rest is up to ARKit to do the heavy augmented reality work.

- What was the purpose?
  The purpose of this app was to help aid foreign visitors in navigating an area in which they aren't familiar with the language. While there are web applications such as Google Translate that can
  translate, none of them are as compact or practical as we believe a phone will allow. This is a project crafted from the hearts of the creators; all four group members have found themselves in this
  situation, and we all struggled having come from El Salvador, India, South Korea, and Nigeria. We see the vision, and we hope you do too.

- Plans for expansion?
  The primary objectives include support for more individuals, meaning expanded language and device support. Furthermore, an implementation of a test mode could prove useful, as a major area lacking
  something like this is in ESL classes.
